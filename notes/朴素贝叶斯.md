# 朴素贝叶斯

贝叶斯思维：主观判断（先验概率）$\rightarrow$ 添加新信息（调整因子）$\rightarrow$ 最终结论（后验概率）

## 核心——贝叶斯定理

###  条件概率

$$
P(A|B) = \frac{P(AB)}{P(B)}
$$

### 贝叶斯定理(逆概率思维)

**问题场景**

存在 **K 类** \(c_1, c_2, \cdots, c_K\)，给定一个新的实例 \(\boxed{x} = (x^{(1)}, x^{(2)}, \cdots, x^{(n)})\)，需要判断该实例归属哪一类。

**后验概率公式**

\(P(Y = c_i | X = x) = \frac{P(X = x| Y = c_i) \cdot P(Y = c_i)}{\sum_{i=1}^{K} P(X = x | Y = c_i) \cdot P(Y = c_i))}\)

- 含义：在给定实例 \(x\) 的条件下，它属于类别 \(c_i\) 的概率。

**分类决策规则**

\(\arg\max_{c_i} P(X =x| Y = c_i) \cdot P(Y = c_i)\)

- 含义：选择使 “似然（\(P(X = x | Y = c_i)\)）× 先验概率（\(P(Y = c_i)\)）” 最大的类别 \(c_i\) 作为实例 \(x\) 的归属类。

**术语解释**

- **先验概率 \(P(Y = c_i)\)**：在未观察到实例特征时，类别 \(c_i\) 出现的概率。
- **似然 \(P(X =x| Y = c_i)\)**：在已知类别为 \(c_i\) 的条件下，观察到实例 \(x\) 的概率。
- **后验概率 \(P(Y = c_i | X = x)\)**：在观察到实例 \(x\) 后，对类别 \(c_i\) 概率的修正。

### 朴素贝叶斯

**前提条件**：

实例之间相互独立
$$
P(Y = c_i | X = x) = \frac{P(Y = c_i) \prod _{j=1}^n P(X^{(J)} = x^{(j)} | Y = c_i)}{\sum ^K _{i=1} P(Y = c_i) \prod _{j=1}^n P(X^{(J)} = x^{(j)} | Y = c_i)}
$$

## 基本方法

#### 训练数据集

$$
T = {(x_1,y_1),(x_2,y_2)...(x_n,y_n)}
$$

- 输入：$\mathcal{X} \subseteq R^n, x \in \mathcal{X}$
- 输出：$\mathcal{Y} = {c_1,c_2,...,c_k}, y \in \mathcal{Y}$

生成方法：学习联合概率分布$P(X,Y)$



### 学习联合概率分布

$$
P(X,Y)
$$

- 先验概率分布：

$$
P(Y = c_i), i = 1,2,...,K
$$

- 条件概率分布：

$$
P(X = x|Y = c_i) = P(X^{(1)} = x^{(1)},...,X^{(n)} = x^{(n)} | Y =c_i)
$$

- 联合概率分布

$$
P(X,Y) = P(X = x|Y = c_i) P(Y = c_i) ,i=1,2,...,K
$$

#### 参数个数

- $x^{j}$的可能取值有$S_j$个
- $y$ 的可能取值有$K$个
- 总个数$K \prod_{j=1}^n S_j$

### 后验概率最大化

- 后验概率

$$
P(Y = c_i | X = x) = \frac{P(Y = c_i) \prod _{j=1}^n P(X^{(J)} = x^{(j)} | Y = c_i)}{\sum ^K _{i=1} P(Y = c_i) \prod _{j=1}^n P(X^{(J)} = x^{(j)} | Y = c_i)}
$$

- 分类

$$
y = arg \underset {c_i}{max} \prod ^n_{j=1}P(X^{(j)} = x^{(j)} |Y=c_i)
$$

- 0-1损失函数

$$
L(Y,\mathcal{f}(X)) = \left\{
    \begin{aligned}
        1 &, \quad Y \neq f(X) \\
        0 &, \quad Y = f(X)
    \end{aligned}
\right.
$$

- 期望风险

$$
R(f) = E[L(Y,f(x))]
$$

- 后验概率最大化

$$
f(x) = arg \underset {c_i}{max}  {P(c_i | X=x)}
$$



### 极大似然估计

- 分类

$$
y = arg \underset {c_i}{max} \prod ^n_{j=1}P(X^{(j)} = x^{(j)} |Y=c_i)
$$

- 先验概率：

$$
P(Y = c_k) = \frac{\sum ^N_{i=1} I(y_i = c_k)}{N} ,K=1,2,...,K
$$

- 条件概率

$$
P(X^{(j)} = a_{jI} |Y=c_k) = \frac{\sum ^N _{i=1} I(x_i ^{j} = a_{jI}, y_i = c_k)}{\sum ^N _{i=1} I(Y_i = c_k)}
$$

#### 极大似然估计原理

- 核心思想：使 **似然函数（即联合密度函数）** 达到最大的参数值。

- 联合密度函数（似然函数的构造）：

  假设 X 的密度函数为 \(f(X, \beta)\)，若简单随机样本 \(X_1, X_2, \cdots, X_N\) 相互独立，则其联合密度函数（似然函数）为： \(L(x_1, \cdots, x_N; \beta) = \prod_{i=1}^{N} f(x_i, \beta)\)

- 似然函数的定义：

  当 \((X_1, X_2, \cdots, X_N)\) 取定值 \((x_1, x_2, \cdots, x_N)\) 时，\(L(x_1, \cdots, x_N; \beta)\) 是 \(\beta\) 的函数，即样本的似然函数。

- 极大似然估计量：

   \(\beta\) 的极大似然估计 \(\hat{\beta}\) 满足： \(\hat{\beta} = \underset{\beta \in \Theta}{\arg \max} L(x_1, \cdots, x_N; \beta)\)

-  记似然函数 \(L(\beta) = L(x_1, \cdots, x_N; \beta)\)



